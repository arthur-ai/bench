## Compare Generation Settings

Outline

In this guide we compare LLM-generated answers to questions using different temperature settings. Higher temperature improves creativity and diversity of answers, but increases the likelihood that responses veer into nonsense.

We compare 3 temperatures and use a custom scorer that evaluates each response based on how many typos it contains

- env
- test suite data
- get LLM responses
- make test suite
- run tests on each set of responses
- view results


env
```
export OPENAI_API_KEY="sk-..."
```

test suite data

```python

```


LLM responses

```python

```

make test suite

```python

```

run tests on each set of responses

```python

```

view results

```python

```
